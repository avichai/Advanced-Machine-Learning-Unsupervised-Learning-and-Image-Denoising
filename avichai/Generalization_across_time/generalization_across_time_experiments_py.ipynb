{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generalization_across_time_experiments.py.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdXu+Ym2uNacsWQobMp7Ys",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avichai/Advanced-Machine-Learning-Unsupervised-Learning-and-Image-Denoising/blob/master/avichai/Generalization_across_time/generalization_across_time_experiments_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq76cxKhq18d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from math import floor\n",
        "import time\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use(\"ggplot\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iN6k0Yaq86j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DEFAULT_NUM_OF_EPOCHS = 200000\n",
        "DEFAULT_NUM_OF_EPOCHS = 300000\n",
        "# DEFAULT_LEARNING_RATE = 0.001\n",
        "DEFAULT_LEARNING_RATE = 0.0001\n",
        "# DEFAULT_LEARNING_RATE = 2e-2\n",
        "DEFAULT_NUMBER_OF_NEURONS = 100\n",
        "DEFAULT_HIDDEN_SIZE = DEFAULT_NUMBER_OF_NEURONS\n",
        "\n",
        "DEFAULT_BATCH_SIZE = 50\n",
        "DATASET_SIZE = DEFAULT_BATCH_SIZE * 4  # = 200\n",
        "DEFAULT_SEQUENCE_LENGTH_TRAIN = 5\n",
        "DEFAULT_SEQUENCE_LENGTH_TEST = 6\n",
        "DEFAULT_LARGEST_TRAIN = 9\n",
        "DEFAULT_LARGEST_TEST = DEFAULT_LARGEST_TRAIN\n",
        "# DEFAULT_LARGEST_TEST = floor(DEFAULT_LARGEST_TRAIN * DEFAULT_SEQUENCE_LENGTH_TRAIN / DEFAULT_SEQUENCE_LENGTH_TEST)\n",
        "\n",
        "RAND_N_NUMBERS = True\n",
        "GET_LAST_INT_ON_TRAIN = False  # if this is True, RAND_N_NUMBERS must be True\n",
        "GET_SUM = True\n",
        "GET_MAX = False\n",
        "\n",
        "PLOT_WEIGHTS = False\n",
        "PLOT_EVERY = DEFAULT_NUM_OF_EPOCHS / 5\n",
        "PRINT_EVERY = DEFAULT_NUM_OF_EPOCHS / 20\n",
        "PLOT_EVERY = 1000\n",
        "PRINT_EVERY = 1000\n",
        "\n",
        "HIDDEN_EQUAL_OUTPUT = False\n",
        "ADD_BIAS = True\n",
        "\n",
        "DEEP_SET = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djHJ-gv1q_Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_sum_tuples(n_examples, n_numbers, largest_train, largest_test, training=True):\n",
        "    largest = largest_train if training else largest_test\n",
        "    X, y = list(), list()\n",
        "    for i in range(n_examples):\n",
        "        in_pattern = np.array(list(map(lambda _: randint(0, largest), range(n_numbers))))\n",
        "        # out_pattern = reduce(lambda x, y: x * y, in_pattern)\n",
        "        if GET_LAST_INT_ON_TRAIN:\n",
        "            assert RAND_N_NUMBERS\n",
        "            if n_numbers < DEFAULT_SEQUENCE_LENGTH_TRAIN or not training:\n",
        "                if GET_SUM:\n",
        "                    out_pattern = sum(in_pattern)\n",
        "                else:\n",
        "                    assert GET_MAX\n",
        "                    out_pattern = max(in_pattern)\n",
        "            else:\n",
        "                out_pattern = 0\n",
        "        if GET_SUM:\n",
        "            out_pattern = sum(in_pattern)\n",
        "        elif GET_MAX:\n",
        "            out_pattern = max(in_pattern)\n",
        "\n",
        "        # X.append(in_pattern / float(largest * n_numbers))\n",
        "        X.append(in_pattern)\n",
        "        # y.append(out_pattern / float(largest * n_numbers))\n",
        "        y.append(out_pattern)\n",
        "    # format as NumPy arrays\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# # invert normalization\n",
        "# def invert(value, n_numbers, largest):\n",
        "#     return round(float(value) * float(largest * n_numbers))\n",
        "\n",
        "\n",
        "def time_since(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def list_to_tensor(lst):\n",
        "    tensor = torch.zeros(len(lst), 1, 1)\n",
        "    for li, num in enumerate(lst):\n",
        "        tensor[li][0][0] = num\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def plot_weights(w1, w2):\n",
        "    _, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    lim1 = np.max(np.abs(w1))\n",
        "    lim2 = np.max(np.abs(w2))\n",
        "    lim = np.maximum(lim1, lim2) + 0.3\n",
        "    for fig, w in [(ax1, w1), (ax2, w2)]:\n",
        "        fig.scatter(w[:, 0], w[:, 1])\n",
        "        fig.axhline(0, color='black')\n",
        "        fig.axvline(0, color='black')\n",
        "        fig.set_xlim([-lim, lim])\n",
        "        fig.set_ylim([-lim, lim])\n",
        "        for i in range(w1.shape[1]):\n",
        "            fig.annotate(str(i), (w[0, i] + 4e-2, w[1, i] + 4e-2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQTjYK0nq_1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + input_size if HIDDEN_EQUAL_OUTPUT else input_size + hidden_size, hidden_size, bias=ADD_BIAS)\n",
        "        self.i2o = nn.Linear(hidden_size, output_size, bias=ADD_BIAS)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = nn.ReLU(self.i2h(combined)).inplace\n",
        "        output = hidden if HIDDEN_EQUAL_OUTPUT else self.i2o(hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "\n",
        "class DEEP_SET(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(DEEP_SET, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size, hidden_size, bias=ADD_BIAS)\n",
        "        self.i2o = nn.Linear(hidden_size, output_size, bias=ADD_BIAS)\n",
        "\n",
        "    def forward(self, sequence_tensor):\n",
        "\n",
        "        hidden = self.init_hidden()\n",
        "        for i in range(sequence_tensor.size()[1]):\n",
        "            hidden += nn.ReLU(self.i2h(torch.t(sequence_tensor[:, i]))).inplace\n",
        "\n",
        "        output = self.i2o(hidden)\n",
        "        return output\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgBK0DkOtfbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_sample_rnn(sequence_tensor, sum_tensor, batch_size):\n",
        "    hidden = model.init_hidden()\n",
        "    output = torch.zeros((1, batch_size))\n",
        "\n",
        "    optimizer.zero_grad()  # this should be the same as rnn.zero_grad()\n",
        "\n",
        "    for i in range(sequence_tensor.size()[1]):\n",
        "        output, hidden = model(torch.t(sequence_tensor[:, i]), hidden)\n",
        "\n",
        "    loss = criterion(output.squeeze(0), sum_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "\n",
        "def train_sample_deepset(sequence_tensor, sum_tensor):\n",
        "    optimizer.zero_grad()  # this should be the same as rnn.zero_grad()\n",
        "\n",
        "    output = model(sequence_tensor)\n",
        "\n",
        "    loss = criterion(output.squeeze(0), sum_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "\n",
        "def train(epocs=DEFAULT_NUM_OF_EPOCHS, batch_size=DEFAULT_BATCH_SIZE, sequence_length=DEFAULT_SEQUENCE_LENGTH_TRAIN, largest_train=DEFAULT_LARGEST_TRAIN,\n",
        "          largest_test=DEFAULT_LARGEST_TEST):\n",
        "    # Keep track of losses for plotting\n",
        "    current_loss = 0\n",
        "    all_losses = []\n",
        "\n",
        "    if not RAND_N_NUMBERS:\n",
        "        numbers_train_all, sum_of_numbers_train_all = random_sum_tuples(DATASET_SIZE, sequence_length, largest_train, largest_test, training=True)\n",
        "\n",
        "    for epoc in range(epocs):\n",
        "        if not RAND_N_NUMBERS:\n",
        "            numbers_train_all, sum_of_numbers_train_all = shuffle(numbers_train_all, sum_of_numbers_train_all)\n",
        "\n",
        "        for i in range(int(DATASET_SIZE / batch_size)):\n",
        "            if not RAND_N_NUMBERS:\n",
        "                numbers_train, sum_of_numbers_train = numbers_train_all[i: i + batch_size], sum_of_numbers_train_all[i: i + batch_size]\n",
        "            else:\n",
        "                numbers_train, sum_of_numbers_train = random_sum_tuples(batch_size, randint(2, sequence_length), largest_train, largest_test, training=True)\n",
        "\n",
        "            sequence_tensor = torch.from_numpy(numbers_train).unsqueeze(-1).type(torch.FloatTensor)\n",
        "            sum_tensor = torch.from_numpy(np.array(sum_of_numbers_train)).type(torch.FloatTensor)\n",
        "\n",
        "            if DEEP_SET:\n",
        "                output, loss = train_sample_deepset(sequence_tensor, sum_tensor)\n",
        "            else:\n",
        "                output, loss = train_sample_rnn(sequence_tensor, sum_tensor, batch_size)\n",
        "            current_loss += loss / PLOT_EVERY\n",
        "\n",
        "        # Print iter number, loss, name and guess\n",
        "        if epoc % PRINT_EVERY == 0:\n",
        "            sequence_to_print = sequence_tensor.squeeze().tolist()[0] if batch_size > 1 else sequence_tensor.squeeze().tolist()\n",
        "            batch_accuracy = (np.round(output[0].data.numpy()) == sum_tensor.data.numpy()).mean()\n",
        "\n",
        "            # batch_accuracy = (np.round(float(output[0]))== int(float(sum_tensor))).mean()\n",
        "            # print(batch_accuracy)\n",
        "            # output_num = invert(float(output[0][0]), sequence_length, largest_train)\n",
        "            output_num = int(float(output[0][0])) if float(output[0][0]) % 1 == 0.0 else float(output[0][0])\n",
        "            # true_sum = invert(float(sum_tensor[0]), sequence_length, largest_train)\n",
        "            true_sum = int(float(sum_tensor[0]))\n",
        "            # sequence_ints = [invert(x, sequence_length, largest_train) for x in sequence_to_print]\n",
        "            sequence_ints = [x for x in sequence_to_print]\n",
        "\n",
        "            correct = '✓' if output_num == true_sum else '✗ (%s)' % true_sum\n",
        "            # print('%d %d%% (%s) %.4f %s / %f %s' % (epoc, epoc / epocs * 100, time_since(start), loss, sequence_ints, output_num, correct))\n",
        "            print('%d %d%% loss: %.4f, 0-1 acc: %.2f,%s / %f %s' % (epoc, epoc / epocs * 100, current_loss, batch_accuracy, sequence_ints, output_num, correct))\n",
        "\n",
        "            # # Add current loss avg to list of losses\n",
        "            # if epoc % PLOT_EVERY == 0:\n",
        "            all_losses.append(current_loss)\n",
        "            # w1 = list(rnn.parameters())[0].data.numpy()\n",
        "            # plot_weights(w1, w1)\n",
        "\n",
        "            current_loss = 0\n",
        "    plt.figure()\n",
        "    plt.plot(all_losses[10:])  # there is a big spike at the begining.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbj7hu2GuFIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Just return an output given a line\n",
        "def evaluate_sample_rnn(sequence_tensor, batch_size):\n",
        "    hidden = model.init_hidden()\n",
        "    output = torch.zeros((1, batch_size))\n",
        "\n",
        "    for i in range(sequence_tensor.size()[1]):\n",
        "        output, hidden = model(torch.t(sequence_tensor[:, i]), output if HIDDEN_EQUAL_OUTPUT else hidden)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# Just return an output given a line\n",
        "def evaluate_sample_deepset(sequence_tensor):\n",
        "    output = model(sequence_tensor)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def evaluate(batch_size=DEFAULT_BATCH_SIZE, sequence_length=DEFAULT_SEQUENCE_LENGTH_TEST, largest_train=DEFAULT_LARGEST_TRAIN, largest_test=DEFAULT_LARGEST_TEST):\n",
        "    expected = []\n",
        "    predicted = []\n",
        "    numbers = []\n",
        "\n",
        "    n_evaluate = 200\n",
        "\n",
        "    # Go through a bunch of examples and record which are correctly guessed\n",
        "    for iteration in range(n_evaluate):\n",
        "        numbers_train, sum_of_numbers_train = random_sum_tuples(batch_size, sequence_length, largest_train, largest_test, training=False)\n",
        "        sequence_tensor = torch.from_numpy(numbers_train).unsqueeze(-1).type(torch.FloatTensor)\n",
        "        sum_tensor = torch.from_numpy(np.array(sum_of_numbers_train)).type(torch.FloatTensor)\n",
        "\n",
        "        if DEEP_SET:\n",
        "            output = evaluate_sample_deepset(sequence_tensor)\n",
        "        else:\n",
        "            output = evaluate_sample_rnn(sequence_tensor, batch_size)\n",
        "\n",
        "        # predicted.append(invert(float(output[0][0]), sequence_length, largest_test))\n",
        "        predicted.append(int(float(output[0][0])) if float(output[0][0]) % 1 == 0.0 else float(output[0][0]))\n",
        "        # expected.append(invert(float(sum_tensor[0]), sequence_length, largest_test))\n",
        "        expected.append(int(float(sum_tensor[0])))\n",
        "\n",
        "        sequence_to_print = sequence_tensor.squeeze().tolist()[0] if batch_size > 1 else sequence_tensor.squeeze().tolist()\n",
        "        # numbers.append([invert(x, sequence_length, largest_test) for x in sequence_to_print])\n",
        "        numbers.append([x for x in sequence_to_print])\n",
        "\n",
        "    rmse = math.sqrt(mean_squared_error(expected, predicted))\n",
        "    print('RMSE: %f' % rmse)\n",
        "    print('Pearson Correlation {}'.format(stats.pearsonr(predicted, expected)))\n",
        "\n",
        "    # show some examples\n",
        "    for i in range(20):\n",
        "        error = (expected[i] - predicted[i]) ** 2\n",
        "        print('Numbers=%s, Expected=%s, Predicted=%s' % (numbers[i], expected[i], predicted[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUwfsAuXuSyR",
        "colab_type": "code",
        "outputId": "005d9701-ddb7-450e-a539-269b964d1725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if DEEP_SET:\n",
        "    model = DEEP_SET(DEFAULT_BATCH_SIZE, DEFAULT_HIDDEN_SIZE, DEFAULT_BATCH_SIZE)\n",
        "else:\n",
        "    model = RNN(DEFAULT_BATCH_SIZE, DEFAULT_HIDDEN_SIZE, DEFAULT_BATCH_SIZE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=DEFAULT_LEARNING_RATE)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train()\n",
        "\n",
        "evaluate()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0% loss: 0.8048, 0-1 acc: 0.02,[4.0, 3.0, 2.0, 8.0] / 4.540646 ✗ (17)\n",
            "1000 0% loss: 122.1931, 0-1 acc: 0.02,[8.0, 5.0, 4.0] / 15.937333 ✗ (17)\n",
            "2000 0% loss: 63.6630, 0-1 acc: 0.16,[1.0, 1.0, 6.0] / 10.932028 ✗ (8)\n",
            "3000 1% loss: 34.4812, 0-1 acc: 0.22,[0.0, 9.0] / 11.020436 ✗ (9)\n",
            "4000 1% loss: 14.9374, 0-1 acc: 0.36,[8.0, 2.0, 0.0] / 9.695628 ✗ (10)\n",
            "5000 1% loss: 3.5049, 0-1 acc: 0.62,[6.0, 0.0, 4.0, 3.0, 5.0] / 18.286592 ✗ (18)\n",
            "6000 2% loss: 0.1375, 0-1 acc: 1.00,[8.0, 0.0, 1.0] / 8.948834 ✗ (9)\n",
            "7000 2% loss: 0.0223, 0-1 acc: 1.00,[7.0, 9.0, 4.0, 0.0, 8.0] / 27.892727 ✗ (28)\n",
            "8000 2% loss: 0.0232, 0-1 acc: 1.00,[0.0, 4.0, 2.0, 9.0, 6.0] / 21.126575 ✗ (21)\n",
            "9000 3% loss: 0.0253, 0-1 acc: 1.00,[7.0, 6.0] / 12.949944 ✗ (13)\n",
            "10000 3% loss: 0.0200, 0-1 acc: 1.00,[0.0, 8.0] / 8.047306 ✗ (8)\n",
            "11000 3% loss: 0.0212, 0-1 acc: 1.00,[0.0, 2.0, 9.0, 6.0] / 16.938057 ✗ (17)\n",
            "12000 4% loss: 0.0229, 0-1 acc: 1.00,[1.0, 4.0, 1.0] / 6.130227 ✗ (6)\n",
            "13000 4% loss: 0.0229, 0-1 acc: 1.00,[3.0, 2.0, 5.0] / 9.989137 ✗ (10)\n",
            "14000 4% loss: 0.0226, 0-1 acc: 1.00,[5.0, 8.0, 4.0, 3.0] / 20.006552 ✗ (20)\n",
            "15000 5% loss: 0.0197, 0-1 acc: 1.00,[0.0, 0.0, 6.0, 0.0, 6.0] / 11.899149 ✗ (12)\n",
            "16000 5% loss: 0.0231, 0-1 acc: 1.00,[8.0, 9.0, 7.0, 3.0] / 27.042622 ✗ (27)\n",
            "17000 5% loss: 0.0238, 0-1 acc: 1.00,[1.0, 7.0] / 8.043556 ✗ (8)\n",
            "18000 6% loss: 0.0178, 0-1 acc: 1.00,[4.0, 2.0] / 6.039533 ✗ (6)\n",
            "19000 6% loss: 0.0218, 0-1 acc: 1.00,[1.0, 4.0] / 4.920310 ✗ (5)\n",
            "20000 6% loss: 0.0211, 0-1 acc: 1.00,[0.0, 9.0, 7.0, 4.0, 9.0] / 28.987116 ✗ (29)\n",
            "21000 7% loss: 0.0205, 0-1 acc: 1.00,[3.0, 2.0, 2.0, 0.0, 8.0] / 15.117579 ✗ (15)\n",
            "22000 7% loss: 0.0232, 0-1 acc: 1.00,[0.0, 5.0, 3.0, 6.0] / 14.102491 ✗ (14)\n",
            "23000 7% loss: 0.0241, 0-1 acc: 1.00,[8.0, 3.0, 1.0, 8.0, 2.0] / 22.026001 ✗ (22)\n",
            "24000 8% loss: 0.0201, 0-1 acc: 1.00,[5.0, 0.0] / 4.949355 ✗ (5)\n",
            "25000 8% loss: 0.0205, 0-1 acc: 1.00,[6.0, 0.0, 2.0, 7.0, 4.0] / 18.911646 ✗ (19)\n",
            "26000 8% loss: 0.0199, 0-1 acc: 1.00,[2.0, 7.0, 3.0, 7.0] / 19.035784 ✗ (19)\n",
            "27000 9% loss: 0.0206, 0-1 acc: 1.00,[6.0, 4.0, 3.0, 7.0] / 20.026297 ✗ (20)\n",
            "28000 9% loss: 0.0199, 0-1 acc: 1.00,[3.0, 0.0, 2.0, 4.0, 5.0] / 14.044083 ✗ (14)\n",
            "29000 9% loss: 0.0210, 0-1 acc: 1.00,[9.0, 8.0, 9.0, 4.0, 6.0] / 36.104645 ✗ (36)\n",
            "30000 10% loss: 0.0219, 0-1 acc: 1.00,[6.0, 0.0, 1.0] / 7.041323 ✗ (7)\n",
            "31000 10% loss: 0.0197, 0-1 acc: 1.00,[7.0, 6.0, 2.0] / 15.005047 ✗ (15)\n",
            "32000 10% loss: 0.0245, 0-1 acc: 1.00,[0.0, 4.0, 4.0] / 8.100781 ✗ (8)\n",
            "33000 11% loss: 0.0199, 0-1 acc: 1.00,[9.0, 4.0] / 13.009850 ✗ (13)\n",
            "34000 11% loss: 0.0252, 0-1 acc: 1.00,[0.0, 7.0, 7.0] / 14.006233 ✗ (14)\n",
            "35000 11% loss: 0.0204, 0-1 acc: 1.00,[8.0, 9.0] / 17.010496 ✗ (17)\n",
            "36000 12% loss: 0.0252, 0-1 acc: 1.00,[7.0, 9.0, 2.0, 6.0] / 23.990435 ✗ (24)\n",
            "37000 12% loss: 0.0186, 0-1 acc: 1.00,[6.0, 9.0, 0.0, 5.0] / 20.114962 ✗ (20)\n",
            "38000 12% loss: 0.0215, 0-1 acc: 1.00,[4.0, 0.0] / 3.998660 ✗ (4)\n",
            "39000 13% loss: 0.0220, 0-1 acc: 1.00,[1.0, 2.0] / 2.910036 ✗ (3)\n",
            "40000 13% loss: 0.0196, 0-1 acc: 1.00,[2.0, 2.0, 4.0] / 8.064553 ✗ (8)\n",
            "41000 13% loss: 0.0193, 0-1 acc: 1.00,[2.0, 4.0, 2.0, 8.0, 1.0] / 16.824144 ✗ (17)\n",
            "42000 14% loss: 0.0231, 0-1 acc: 1.00,[3.0, 4.0, 5.0] / 12.046892 ✗ (12)\n",
            "43000 14% loss: 0.0213, 0-1 acc: 1.00,[4.0, 9.0, 8.0, 7.0, 2.0] / 29.964743 ✗ (30)\n",
            "44000 14% loss: 0.0205, 0-1 acc: 1.00,[4.0, 4.0, 4.0, 7.0, 9.0] / 27.969177 ✗ (28)\n",
            "45000 15% loss: 0.0216, 0-1 acc: 1.00,[0.0, 2.0] / 2.065046 ✗ (2)\n",
            "46000 15% loss: 0.0206, 0-1 acc: 1.00,[3.0, 5.0, 2.0, 7.0] / 16.871895 ✗ (17)\n",
            "47000 15% loss: 0.0179, 0-1 acc: 1.00,[0.0, 0.0, 5.0] / 4.865389 ✗ (5)\n",
            "48000 16% loss: 0.0199, 0-1 acc: 1.00,[4.0, 7.0, 3.0, 1.0, 1.0] / 16.091061 ✗ (16)\n",
            "49000 16% loss: 0.0234, 0-1 acc: 1.00,[6.0, 1.0, 5.0] / 12.054327 ✗ (12)\n",
            "50000 16% loss: 0.0179, 0-1 acc: 1.00,[1.0, 0.0] / 0.980817 ✗ (1)\n",
            "51000 17% loss: 0.0218, 0-1 acc: 1.00,[4.0, 5.0, 4.0, 5.0, 3.0] / 21.021311 ✗ (21)\n",
            "52000 17% loss: 0.0186, 0-1 acc: 1.00,[2.0, 8.0, 2.0, 7.0] / 18.938919 ✗ (19)\n",
            "53000 17% loss: 0.0235, 0-1 acc: 1.00,[8.0, 4.0, 9.0, 9.0] / 30.033712 ✗ (30)\n",
            "54000 18% loss: 0.0228, 0-1 acc: 1.00,[3.0, 7.0, 5.0, 2.0, 8.0] / 24.980095 ✗ (25)\n",
            "55000 18% loss: 0.0179, 0-1 acc: 1.00,[7.0, 4.0, 8.0, 0.0] / 18.954226 ✗ (19)\n",
            "56000 18% loss: 0.0254, 0-1 acc: 1.00,[9.0, 7.0, 5.0] / 20.934664 ✗ (21)\n",
            "57000 19% loss: 0.0194, 0-1 acc: 1.00,[3.0, 1.0, 0.0] / 3.985985 ✗ (4)\n",
            "58000 19% loss: 0.0222, 0-1 acc: 1.00,[8.0, 4.0, 1.0, 5.0, 5.0] / 22.987745 ✗ (23)\n",
            "59000 19% loss: 0.0194, 0-1 acc: 1.00,[3.0, 3.0, 6.0, 4.0, 7.0] / 23.097589 ✗ (23)\n",
            "60000 20% loss: 0.0229, 0-1 acc: 1.00,[0.0, 7.0, 6.0, 3.0] / 15.837235 ✗ (16)\n",
            "61000 20% loss: 0.0200, 0-1 acc: 1.00,[8.0, 4.0, 0.0, 2.0, 3.0] / 16.927893 ✗ (17)\n",
            "62000 20% loss: 0.0198, 0-1 acc: 1.00,[0.0, 5.0, 1.0, 5.0, 7.0] / 17.987387 ✗ (18)\n",
            "63000 21% loss: 0.0251, 0-1 acc: 1.00,[3.0, 0.0] / 3.024474 ✗ (3)\n",
            "64000 21% loss: 0.0161, 0-1 acc: 1.00,[4.0, 7.0, 9.0, 3.0, 1.0] / 24.118206 ✗ (24)\n",
            "65000 21% loss: 0.0223, 0-1 acc: 1.00,[8.0, 5.0] / 13.009701 ✗ (13)\n",
            "66000 22% loss: 0.0210, 0-1 acc: 1.00,[8.0, 1.0, 4.0] / 13.029470 ✗ (13)\n",
            "67000 22% loss: 0.0199, 0-1 acc: 1.00,[8.0, 8.0, 3.0] / 18.962351 ✗ (19)\n",
            "68000 22% loss: 0.0221, 0-1 acc: 1.00,[4.0, 7.0, 7.0, 1.0] / 19.077143 ✗ (19)\n",
            "69000 23% loss: 0.0199, 0-1 acc: 1.00,[1.0, 2.0, 7.0, 9.0, 0.0] / 18.865677 ✗ (19)\n",
            "70000 23% loss: 0.0183, 0-1 acc: 1.00,[2.0, 9.0, 7.0, 5.0] / 23.129398 ✗ (23)\n",
            "71000 23% loss: 0.0207, 0-1 acc: 1.00,[7.0, 3.0, 0.0, 7.0] / 17.220133 ✗ (17)\n",
            "72000 24% loss: 0.0186, 0-1 acc: 1.00,[6.0, 1.0, 9.0, 8.0, 9.0] / 33.091682 ✗ (33)\n",
            "73000 24% loss: 0.0205, 0-1 acc: 1.00,[3.0, 5.0, 4.0] / 12.092529 ✗ (12)\n",
            "74000 24% loss: 0.0195, 0-1 acc: 1.00,[4.0, 0.0, 1.0, 0.0, 1.0] / 6.017080 ✗ (6)\n",
            "75000 25% loss: 0.0185, 0-1 acc: 1.00,[1.0, 5.0, 5.0, 1.0, 9.0] / 20.837997 ✗ (21)\n",
            "76000 25% loss: 0.0200, 0-1 acc: 1.00,[1.0, 5.0] / 5.998963 ✗ (6)\n",
            "77000 25% loss: 0.0209, 0-1 acc: 1.00,[9.0, 4.0, 1.0, 5.0, 4.0] / 23.005579 ✗ (23)\n",
            "78000 26% loss: 0.0194, 0-1 acc: 1.00,[2.0, 0.0] / 1.996593 ✗ (2)\n",
            "79000 26% loss: 0.0200, 0-1 acc: 1.00,[6.0, 1.0, 6.0] / 12.934686 ✗ (13)\n",
            "80000 26% loss: 0.0197, 0-1 acc: 1.00,[2.0, 2.0, 2.0, 9.0] / 15.074958 ✗ (15)\n",
            "81000 27% loss: 0.0189, 0-1 acc: 1.00,[6.0, 4.0, 9.0, 5.0, 0.0] / 23.935873 ✗ (24)\n",
            "82000 27% loss: 0.0190, 0-1 acc: 1.00,[7.0, 6.0, 8.0, 5.0] / 26.052725 ✗ (26)\n",
            "83000 27% loss: 0.0198, 0-1 acc: 0.98,[9.0, 5.0, 1.0, 5.0, 5.0] / 24.645391 ✗ (25)\n",
            "84000 28% loss: 0.0204, 0-1 acc: 1.00,[7.0, 4.0] / 10.999073 ✗ (11)\n",
            "85000 28% loss: 0.0180, 0-1 acc: 1.00,[7.0, 2.0, 8.0, 7.0, 5.0] / 28.987833 ✗ (29)\n",
            "86000 28% loss: 0.0208, 0-1 acc: 1.00,[8.0, 0.0] / 8.009727 ✗ (8)\n",
            "87000 28% loss: 0.0232, 0-1 acc: 1.00,[3.0, 3.0, 0.0, 5.0, 7.0] / 18.286261 ✗ (18)\n",
            "88000 29% loss: 0.0189, 0-1 acc: 1.00,[0.0, 4.0, 0.0] / 3.969025 ✗ (4)\n",
            "89000 29% loss: 0.0213, 0-1 acc: 1.00,[9.0, 7.0, 2.0, 1.0] / 19.004831 ✗ (19)\n",
            "90000 30% loss: 0.0219, 0-1 acc: 1.00,[3.0, 5.0] / 7.996610 ✗ (8)\n",
            "91000 30% loss: 0.0228, 0-1 acc: 1.00,[1.0, 6.0, 3.0, 9.0, 9.0] / 27.979057 ✗ (28)\n",
            "92000 30% loss: 0.0208, 0-1 acc: 1.00,[2.0, 2.0, 3.0, 7.0, 0.0] / 13.950376 ✗ (14)\n",
            "93000 31% loss: 0.0194, 0-1 acc: 1.00,[0.0, 4.0, 8.0] / 12.142153 ✗ (12)\n",
            "94000 31% loss: 0.0216, 0-1 acc: 1.00,[2.0, 4.0, 5.0, 3.0, 9.0] / 22.877996 ✗ (23)\n",
            "95000 31% loss: 0.0195, 0-1 acc: 1.00,[3.0, 2.0] / 4.972536 ✗ (5)\n",
            "96000 32% loss: 0.0182, 0-1 acc: 1.00,[2.0, 1.0, 0.0] / 2.993289 ✗ (3)\n",
            "97000 32% loss: 0.0191, 0-1 acc: 1.00,[5.0, 8.0, 6.0, 2.0] / 20.989210 ✗ (21)\n",
            "98000 32% loss: 0.0221, 0-1 acc: 1.00,[6.0, 9.0, 5.0, 9.0] / 28.944576 ✗ (29)\n",
            "99000 33% loss: 0.0198, 0-1 acc: 1.00,[1.0, 0.0] / 0.982120 ✗ (1)\n",
            "100000 33% loss: 0.0204, 0-1 acc: 1.00,[0.0, 2.0, 3.0, 3.0] / 8.008862 ✗ (8)\n",
            "101000 33% loss: 0.0200, 0-1 acc: 1.00,[9.0, 5.0, 6.0, 0.0, 1.0] / 20.977011 ✗ (21)\n",
            "102000 34% loss: 0.0228, 0-1 acc: 1.00,[0.0, 8.0, 9.0] / 17.018671 ✗ (17)\n",
            "103000 34% loss: 0.0199, 0-1 acc: 1.00,[1.0, 9.0, 3.0, 8.0] / 20.885492 ✗ (21)\n",
            "104000 34% loss: 0.0193, 0-1 acc: 1.00,[0.0, 7.0, 4.0, 9.0, 4.0] / 23.970875 ✗ (24)\n",
            "105000 35% loss: 0.0228, 0-1 acc: 1.00,[8.0, 7.0, 0.0, 3.0] / 18.025627 ✗ (18)\n",
            "106000 35% loss: 0.0198, 0-1 acc: 1.00,[4.0, 6.0, 0.0] / 9.976930 ✗ (10)\n",
            "107000 35% loss: 0.0197, 0-1 acc: 1.00,[4.0, 5.0, 8.0] / 16.992840 ✗ (17)\n",
            "108000 36% loss: 0.0198, 0-1 acc: 1.00,[9.0, 7.0, 1.0, 5.0] / 21.997025 ✗ (22)\n",
            "109000 36% loss: 0.0197, 0-1 acc: 1.00,[6.0, 0.0, 6.0, 9.0] / 21.020021 ✗ (21)\n",
            "110000 36% loss: 0.0187, 0-1 acc: 1.00,[7.0, 2.0, 3.0] / 11.983740 ✗ (12)\n",
            "111000 37% loss: 0.0201, 0-1 acc: 1.00,[6.0, 7.0, 6.0] / 18.983454 ✗ (19)\n",
            "112000 37% loss: 0.0192, 0-1 acc: 1.00,[6.0, 7.0] / 13.061961 ✗ (13)\n",
            "113000 37% loss: 0.0205, 0-1 acc: 1.00,[7.0, 4.0, 1.0, 1.0] / 12.951284 ✗ (13)\n",
            "114000 38% loss: 0.0184, 0-1 acc: 1.00,[2.0, 8.0, 0.0] / 9.962927 ✗ (10)\n",
            "115000 38% loss: 0.0215, 0-1 acc: 1.00,[2.0, 7.0, 3.0, 1.0, 1.0] / 13.926492 ✗ (14)\n",
            "116000 38% loss: 0.0207, 0-1 acc: 1.00,[9.0, 4.0, 4.0, 7.0, 5.0] / 28.943943 ✗ (29)\n",
            "117000 39% loss: 0.0233, 0-1 acc: 1.00,[5.0, 7.0, 3.0, 2.0] / 17.003916 ✗ (17)\n",
            "118000 39% loss: 0.0173, 0-1 acc: 1.00,[4.0, 3.0, 2.0, 2.0] / 11.021771 ✗ (11)\n",
            "119000 39% loss: 0.0201, 0-1 acc: 1.00,[8.0, 6.0, 8.0, 4.0] / 26.028530 ✗ (26)\n",
            "120000 40% loss: 0.0203, 0-1 acc: 1.00,[3.0, 5.0, 7.0, 2.0, 0.0] / 17.096642 ✗ (17)\n",
            "121000 40% loss: 0.0182, 0-1 acc: 1.00,[4.0, 2.0, 8.0, 4.0, 6.0] / 24.012400 ✗ (24)\n",
            "122000 40% loss: 0.0232, 0-1 acc: 1.00,[8.0, 7.0, 4.0, 1.0] / 19.915606 ✗ (20)\n",
            "123000 41% loss: 0.0182, 0-1 acc: 1.00,[1.0, 2.0] / 2.976616 ✗ (3)\n",
            "124000 41% loss: 0.0209, 0-1 acc: 1.00,[0.0, 3.0, 0.0, 8.0] / 11.005244 ✗ (11)\n",
            "125000 41% loss: 0.0192, 0-1 acc: 1.00,[8.0, 3.0, 1.0, 4.0, 9.0] / 25.013847 ✗ (25)\n",
            "126000 42% loss: 0.0207, 0-1 acc: 1.00,[5.0, 7.0, 7.0, 6.0, 9.0] / 33.958889 ✗ (34)\n",
            "127000 42% loss: 0.0182, 0-1 acc: 1.00,[0.0, 9.0] / 9.003436 ✗ (9)\n",
            "128000 42% loss: 0.0205, 0-1 acc: 1.00,[3.0, 7.0, 9.0, 5.0, 8.0] / 31.972088 ✗ (32)\n",
            "129000 43% loss: 0.0194, 0-1 acc: 1.00,[7.0, 8.0, 6.0, 5.0, 7.0] / 32.997292 ✗ (33)\n",
            "130000 43% loss: 0.0197, 0-1 acc: 1.00,[5.0, 2.0] / 7.086934 ✗ (7)\n",
            "131000 43% loss: 0.0215, 0-1 acc: 1.00,[0.0, 6.0, 8.0] / 13.969978 ✗ (14)\n",
            "132000 44% loss: 0.0198, 0-1 acc: 1.00,[0.0, 4.0, 0.0, 9.0] / 13.297988 ✗ (13)\n",
            "133000 44% loss: 0.0218, 0-1 acc: 1.00,[7.0, 5.0, 0.0, 1.0] / 12.905925 ✗ (13)\n",
            "134000 44% loss: 0.0183, 0-1 acc: 1.00,[7.0, 9.0, 5.0] / 20.987495 ✗ (21)\n",
            "135000 45% loss: 0.0199, 0-1 acc: 1.00,[8.0, 0.0] / 8.069171 ✗ (8)\n",
            "136000 45% loss: 0.0230, 0-1 acc: 1.00,[9.0, 5.0, 1.0] / 14.975026 ✗ (15)\n",
            "137000 45% loss: 0.0162, 0-1 acc: 1.00,[8.0, 9.0] / 17.014109 ✗ (17)\n",
            "138000 46% loss: 0.0197, 0-1 acc: 1.00,[6.0, 4.0, 6.0, 8.0] / 23.922485 ✗ (24)\n",
            "139000 46% loss: 0.0180, 0-1 acc: 1.00,[5.0, 6.0] / 11.039177 ✗ (11)\n",
            "140000 46% loss: 0.0208, 0-1 acc: 1.00,[8.0, 4.0] / 12.040285 ✗ (12)\n",
            "141000 47% loss: 0.0215, 0-1 acc: 1.00,[6.0, 3.0, 5.0, 7.0] / 21.015791 ✗ (21)\n",
            "142000 47% loss: 0.0204, 0-1 acc: 1.00,[4.0, 2.0, 6.0, 6.0] / 18.020666 ✗ (18)\n",
            "143000 47% loss: 0.0202, 0-1 acc: 1.00,[8.0, 4.0, 4.0, 1.0, 9.0] / 25.992296 ✗ (26)\n",
            "144000 48% loss: 0.0212, 0-1 acc: 1.00,[6.0, 1.0, 9.0, 2.0, 0.0] / 17.993441 ✗ (18)\n",
            "145000 48% loss: 0.0174, 0-1 acc: 1.00,[4.0, 3.0] / 6.984002 ✗ (7)\n",
            "146000 48% loss: 0.0202, 0-1 acc: 1.00,[8.0, 9.0, 2.0] / 18.915802 ✗ (19)\n",
            "147000 49% loss: 0.0179, 0-1 acc: 1.00,[0.0, 4.0, 4.0] / 8.042192 ✗ (8)\n",
            "148000 49% loss: 0.0189, 0-1 acc: 1.00,[1.0, 3.0, 9.0, 7.0] / 20.002296 ✗ (20)\n",
            "149000 49% loss: 0.0216, 0-1 acc: 1.00,[0.0, 2.0] / 1.980270 ✗ (2)\n",
            "150000 50% loss: 0.0169, 0-1 acc: 1.00,[9.0, 6.0, 9.0, 7.0, 3.0] / 34.064869 ✗ (34)\n",
            "151000 50% loss: 0.0220, 0-1 acc: 1.00,[0.0, 3.0, 9.0] / 11.982259 ✗ (12)\n",
            "152000 50% loss: 0.0214, 0-1 acc: 1.00,[5.0, 1.0, 5.0, 8.0] / 19.010296 ✗ (19)\n",
            "153000 51% loss: 0.0180, 0-1 acc: 1.00,[0.0, 2.0, 1.0, 9.0] / 12.018388 ✗ (12)\n",
            "154000 51% loss: 0.0215, 0-1 acc: 1.00,[5.0, 9.0, 3.0, 9.0, 2.0] / 28.115072 ✗ (28)\n",
            "155000 51% loss: 0.0192, 0-1 acc: 1.00,[6.0, 6.0, 8.0, 3.0, 0.0] / 23.026506 ✗ (23)\n",
            "156000 52% loss: 0.0196, 0-1 acc: 1.00,[5.0, 2.0, 2.0, 1.0, 9.0] / 19.050098 ✗ (19)\n",
            "157000 52% loss: 0.0200, 0-1 acc: 1.00,[0.0, 0.0, 7.0, 3.0] / 10.017074 ✗ (10)\n",
            "158000 52% loss: 0.0178, 0-1 acc: 1.00,[6.0, 2.0] / 7.940426 ✗ (8)\n",
            "159000 53% loss: 0.0196, 0-1 acc: 1.00,[2.0, 5.0] / 7.032359 ✗ (7)\n",
            "160000 53% loss: 0.0203, 0-1 acc: 1.00,[8.0, 9.0] / 17.002045 ✗ (17)\n",
            "161000 53% loss: 0.0201, 0-1 acc: 1.00,[9.0, 0.0, 8.0, 6.0, 7.0] / 30.016541 ✗ (30)\n",
            "162000 54% loss: 0.0170, 0-1 acc: 1.00,[3.0, 3.0, 0.0] / 5.953597 ✗ (6)\n",
            "163000 54% loss: 0.0242, 0-1 acc: 1.00,[4.0, 1.0, 3.0, 7.0] / 14.969232 ✗ (15)\n",
            "164000 54% loss: 0.0172, 0-1 acc: 1.00,[0.0, 1.0] / 1.012309 ✗ (1)\n",
            "165000 55% loss: 0.0214, 0-1 acc: 1.00,[8.0, 6.0, 4.0] / 17.932880 ✗ (18)\n",
            "166000 55% loss: 0.0184, 0-1 acc: 1.00,[8.0, 5.0] / 13.042874 ✗ (13)\n",
            "167000 55% loss: 0.0211, 0-1 acc: 1.00,[8.0, 4.0, 3.0, 1.0, 7.0] / 23.025648 ✗ (23)\n",
            "168000 56% loss: 0.0181, 0-1 acc: 1.00,[0.0, 3.0] / 3.021857 ✗ (3)\n",
            "169000 56% loss: 0.0248, 0-1 acc: 1.00,[3.0, 9.0] / 11.992314 ✗ (12)\n",
            "170000 56% loss: 0.0160, 0-1 acc: 1.00,[9.0, 1.0, 6.0] / 16.017666 ✗ (16)\n",
            "171000 56% loss: 0.0179, 0-1 acc: 1.00,[2.0, 7.0, 0.0, 1.0, 8.0] / 17.986879 ✗ (18)\n",
            "172000 57% loss: 0.0217, 0-1 acc: 1.00,[9.0, 0.0, 2.0, 0.0, 3.0] / 13.976261 ✗ (14)\n",
            "173000 57% loss: 0.0186, 0-1 acc: 1.00,[9.0, 6.0] / 14.987219 ✗ (15)\n",
            "174000 57% loss: 0.0221, 0-1 acc: 1.00,[1.0, 9.0, 9.0, 9.0, 0.0] / 28.009481 ✗ (28)\n",
            "175000 58% loss: 0.0174, 0-1 acc: 1.00,[7.0, 5.0] / 12.005167 ✗ (12)\n",
            "176000 58% loss: 0.0210, 0-1 acc: 1.00,[1.0, 4.0, 8.0, 7.0, 3.0] / 22.992722 ✗ (23)\n",
            "177000 59% loss: 0.0176, 0-1 acc: 1.00,[7.0, 9.0, 0.0] / 15.997107 ✗ (16)\n",
            "178000 59% loss: 0.0207, 0-1 acc: 1.00,[0.0, 4.0] / 3.813930 ✗ (4)\n",
            "179000 59% loss: 0.0187, 0-1 acc: 1.00,[3.0, 4.0] / 7.006397 ✗ (7)\n",
            "180000 60% loss: 0.0212, 0-1 acc: 1.00,[5.0, 1.0, 6.0] / 11.984212 ✗ (12)\n",
            "181000 60% loss: 0.0176, 0-1 acc: 1.00,[0.0, 5.0, 5.0, 0.0, 0.0] / 9.989067 ✗ (10)\n",
            "182000 60% loss: 0.0182, 0-1 acc: 1.00,[2.0, 0.0] / 1.982846 ✗ (2)\n",
            "183000 61% loss: 0.0179, 0-1 acc: 1.00,[5.0, 9.0, 3.0] / 17.171726 ✗ (17)\n",
            "184000 61% loss: 0.0184, 0-1 acc: 1.00,[4.0, 7.0, 7.0, 5.0] / 23.042229 ✗ (23)\n",
            "185000 61% loss: 0.0196, 0-1 acc: 1.00,[9.0, 4.0, 3.0, 9.0, 0.0] / 24.901381 ✗ (25)\n",
            "186000 62% loss: 0.0183, 0-1 acc: 1.00,[8.0, 4.0] / 11.994593 ✗ (12)\n",
            "187000 62% loss: 0.0201, 0-1 acc: 1.00,[4.0, 1.0, 4.0, 2.0, 3.0] / 14.061561 ✗ (14)\n",
            "188000 62% loss: 0.0184, 0-1 acc: 1.00,[8.0, 7.0, 1.0] / 15.933109 ✗ (16)\n",
            "189000 63% loss: 0.0183, 0-1 acc: 1.00,[1.0, 7.0, 4.0, 6.0, 2.0] / 20.112501 ✗ (20)\n",
            "190000 63% loss: 0.0175, 0-1 acc: 1.00,[3.0, 4.0] / 7.034897 ✗ (7)\n",
            "191000 63% loss: 0.0202, 0-1 acc: 1.00,[3.0, 0.0, 3.0, 1.0] / 7.012112 ✗ (7)\n",
            "192000 64% loss: 0.0188, 0-1 acc: 1.00,[7.0, 9.0, 6.0, 4.0] / 25.995314 ✗ (26)\n",
            "193000 64% loss: 0.0169, 0-1 acc: 1.00,[8.0, 6.0, 9.0, 7.0] / 29.982855 ✗ (30)\n",
            "194000 64% loss: 0.0187, 0-1 acc: 1.00,[8.0, 9.0, 0.0] / 16.980650 ✗ (17)\n",
            "195000 65% loss: 0.0232, 0-1 acc: 1.00,[0.0, 1.0, 4.0] / 5.026516 ✗ (5)\n",
            "196000 65% loss: 0.0201, 0-1 acc: 1.00,[7.0, 5.0] / 12.003836 ✗ (12)\n",
            "197000 65% loss: 0.0189, 0-1 acc: 1.00,[9.0, 0.0] / 8.996446 ✗ (9)\n",
            "198000 66% loss: 0.0202, 0-1 acc: 1.00,[7.0, 2.0, 8.0] / 17.018671 ✗ (17)\n",
            "199000 66% loss: 0.0193, 0-1 acc: 1.00,[0.0, 8.0, 2.0, 5.0] / 15.012599 ✗ (15)\n",
            "200000 66% loss: 0.0187, 0-1 acc: 0.98,[5.0, 1.0, 6.0, 5.0, 1.0] / 18.103786 ✗ (18)\n",
            "201000 67% loss: 0.0199, 0-1 acc: 1.00,[2.0, 1.0, 0.0, 7.0, 4.0] / 13.939760 ✗ (14)\n",
            "202000 67% loss: 0.0185, 0-1 acc: 1.00,[1.0, 2.0, 5.0, 6.0] / 13.909580 ✗ (14)\n",
            "203000 67% loss: 0.0184, 0-1 acc: 1.00,[9.0, 9.0, 7.0, 9.0] / 33.892460 ✗ (34)\n",
            "204000 68% loss: 0.0186, 0-1 acc: 1.00,[6.0, 1.0, 3.0] / 9.975454 ✗ (10)\n",
            "205000 68% loss: 0.0178, 0-1 acc: 1.00,[7.0, 5.0, 6.0, 0.0] / 18.145393 ✗ (18)\n",
            "206000 68% loss: 0.0194, 0-1 acc: 1.00,[6.0, 8.0, 0.0, 8.0] / 21.983692 ✗ (22)\n",
            "207000 69% loss: 0.0178, 0-1 acc: 1.00,[9.0, 9.0, 3.0] / 21.056284 ✗ (21)\n",
            "208000 69% loss: 0.0190, 0-1 acc: 1.00,[0.0, 1.0, 6.0, 8.0, 3.0] / 18.052370 ✗ (18)\n",
            "209000 69% loss: 0.0185, 0-1 acc: 1.00,[4.0, 8.0] / 11.959359 ✗ (12)\n",
            "210000 70% loss: 0.0231, 0-1 acc: 1.00,[0.0, 0.0] / 0.022984 ✗ (0)\n",
            "211000 70% loss: 0.0183, 0-1 acc: 1.00,[6.0, 4.0, 1.0, 1.0] / 12.019108 ✗ (12)\n",
            "212000 70% loss: 0.0186, 0-1 acc: 1.00,[0.0, 6.0, 2.0] / 8.020690 ✗ (8)\n",
            "213000 71% loss: 0.0173, 0-1 acc: 1.00,[0.0, 5.0, 0.0, 3.0] / 7.944640 ✗ (8)\n",
            "214000 71% loss: 0.0193, 0-1 acc: 1.00,[1.0, 4.0, 6.0, 3.0, 8.0] / 21.937452 ✗ (22)\n",
            "215000 71% loss: 0.0187, 0-1 acc: 1.00,[3.0, 9.0] / 12.065413 ✗ (12)\n",
            "216000 72% loss: 0.0171, 0-1 acc: 1.00,[3.0, 8.0, 1.0] / 11.993188 ✗ (12)\n",
            "217000 72% loss: 0.0206, 0-1 acc: 1.00,[1.0, 5.0] / 6.002855 ✗ (6)\n",
            "218000 72% loss: 0.0218, 0-1 acc: 1.00,[6.0, 9.0, 4.0] / 18.881132 ✗ (19)\n",
            "219000 73% loss: 0.0158, 0-1 acc: 1.00,[8.0, 5.0, 4.0, 3.0] / 20.011988 ✗ (20)\n",
            "220000 73% loss: 0.0193, 0-1 acc: 1.00,[5.0, 6.0, 8.0, 9.0, 4.0] / 32.118225 ✗ (32)\n",
            "221000 73% loss: 0.0196, 0-1 acc: 1.00,[2.0, 5.0] / 6.975334 ✗ (7)\n",
            "222000 74% loss: 0.0168, 0-1 acc: 1.00,[7.0, 8.0, 8.0] / 22.985006 ✗ (23)\n",
            "223000 74% loss: 0.0181, 0-1 acc: 1.00,[5.0, 5.0] / 10.029340 ✗ (10)\n",
            "224000 74% loss: 0.0207, 0-1 acc: 1.00,[7.0, 4.0] / 11.069171 ✗ (11)\n",
            "225000 75% loss: 0.0192, 0-1 acc: 1.00,[9.0, 5.0] / 13.954720 ✗ (14)\n",
            "226000 75% loss: 0.0175, 0-1 acc: 1.00,[3.0, 8.0] / 10.975682 ✗ (11)\n",
            "227000 75% loss: 0.0192, 0-1 acc: 1.00,[4.0, 2.0, 2.0] / 7.882693 ✗ (8)\n",
            "228000 76% loss: 0.0222, 0-1 acc: 1.00,[0.0, 1.0, 3.0, 2.0] / 6.031665 ✗ (6)\n",
            "229000 76% loss: 0.0175, 0-1 acc: 1.00,[6.0, 8.0] / 14.002721 ✗ (14)\n",
            "230000 76% loss: 0.0235, 0-1 acc: 1.00,[3.0, 1.0, 6.0, 6.0] / 15.975926 ✗ (16)\n",
            "231000 77% loss: 0.0174, 0-1 acc: 1.00,[0.0, 5.0, 5.0, 9.0, 5.0] / 23.998583 ✗ (24)\n",
            "232000 77% loss: 0.0192, 0-1 acc: 1.00,[7.0, 4.0, 2.0, 0.0, 3.0] / 16.005972 ✗ (16)\n",
            "233000 77% loss: 0.0194, 0-1 acc: 1.00,[1.0, 5.0, 5.0, 1.0, 3.0] / 15.015763 ✗ (15)\n",
            "234000 78% loss: 0.0215, 0-1 acc: 1.00,[0.0, 8.0, 1.0, 0.0] / 8.966005 ✗ (9)\n",
            "235000 78% loss: 0.0153, 0-1 acc: 1.00,[2.0, 1.0, 6.0, 4.0, 0.0] / 12.919010 ✗ (13)\n",
            "236000 78% loss: 0.0183, 0-1 acc: 1.00,[8.0, 6.0, 4.0, 6.0] / 24.015902 ✗ (24)\n",
            "237000 79% loss: 0.0179, 0-1 acc: 1.00,[1.0, 5.0, 7.0] / 13.002358 ✗ (13)\n",
            "238000 79% loss: 0.0197, 0-1 acc: 1.00,[2.0, 6.0, 4.0] / 12.056469 ✗ (12)\n",
            "239000 79% loss: 0.0182, 0-1 acc: 1.00,[5.0, 1.0, 7.0, 3.0, 3.0] / 19.096962 ✗ (19)\n",
            "240000 80% loss: 0.0196, 0-1 acc: 1.00,[1.0, 0.0] / 1.041291 ✗ (1)\n",
            "241000 80% loss: 0.0166, 0-1 acc: 1.00,[1.0, 4.0] / 4.978893 ✗ (5)\n",
            "242000 80% loss: 0.0202, 0-1 acc: 1.00,[3.0, 0.0] / 3.005152 ✗ (3)\n",
            "243000 81% loss: 0.0182, 0-1 acc: 1.00,[0.0, 3.0, 0.0, 3.0, 7.0] / 12.798416 ✗ (13)\n",
            "244000 81% loss: 0.0194, 0-1 acc: 1.00,[2.0, 4.0, 9.0, 8.0, 5.0] / 27.988365 ✗ (28)\n",
            "245000 81% loss: 0.0171, 0-1 acc: 1.00,[7.0, 2.0, 8.0, 8.0, 9.0] / 34.056717 ✗ (34)\n",
            "246000 82% loss: 0.0188, 0-1 acc: 1.00,[1.0, 6.0, 9.0] / 16.108881 ✗ (16)\n",
            "247000 82% loss: 0.0197, 0-1 acc: 1.00,[9.0, 9.0, 3.0, 7.0] / 27.969034 ✗ (28)\n",
            "248000 82% loss: 0.0179, 0-1 acc: 1.00,[0.0, 3.0] / 2.980725 ✗ (3)\n",
            "249000 83% loss: 0.0186, 0-1 acc: 1.00,[7.0, 6.0] / 12.999854 ✗ (13)\n",
            "250000 83% loss: 0.0179, 0-1 acc: 1.00,[6.0, 9.0] / 15.035603 ✗ (15)\n",
            "251000 83% loss: 0.0179, 0-1 acc: 1.00,[7.0, 4.0] / 11.021385 ✗ (11)\n",
            "252000 84% loss: 0.0198, 0-1 acc: 1.00,[2.0, 8.0] / 10.098639 ✗ (10)\n",
            "253000 84% loss: 0.0161, 0-1 acc: 1.00,[4.0, 7.0, 9.0, 6.0] / 26.053896 ✗ (26)\n",
            "254000 84% loss: 0.0199, 0-1 acc: 1.00,[0.0, 8.0, 9.0, 3.0, 0.0] / 20.000765 ✗ (20)\n",
            "255000 85% loss: 0.0201, 0-1 acc: 1.00,[3.0, 3.0, 2.0] / 8.036332 ✗ (8)\n",
            "256000 85% loss: 0.0182, 0-1 acc: 1.00,[7.0, 0.0, 8.0, 9.0] / 24.021463 ✗ (24)\n",
            "257000 85% loss: 0.0166, 0-1 acc: 1.00,[4.0, 0.0] / 4.120888 ✗ (4)\n",
            "258000 86% loss: 0.0188, 0-1 acc: 1.00,[7.0, 9.0, 0.0, 8.0, 9.0] / 33.120518 ✗ (33)\n",
            "259000 86% loss: 0.0195, 0-1 acc: 1.00,[6.0, 6.0, 3.0, 1.0] / 15.823003 ✗ (16)\n",
            "260000 86% loss: 0.0183, 0-1 acc: 1.00,[4.0, 0.0, 0.0] / 3.980693 ✗ (4)\n",
            "261000 87% loss: 0.0178, 0-1 acc: 1.00,[6.0, 1.0, 7.0] / 13.970073 ✗ (14)\n",
            "262000 87% loss: 0.0184, 0-1 acc: 1.00,[2.0, 8.0] / 9.992833 ✗ (10)\n",
            "263000 87% loss: 0.0194, 0-1 acc: 1.00,[2.0, 5.0, 4.0, 8.0] / 19.035975 ✗ (19)\n",
            "264000 88% loss: 0.0198, 0-1 acc: 1.00,[5.0, 0.0, 8.0, 9.0, 0.0] / 21.869579 ✗ (22)\n",
            "265000 88% loss: 0.0195, 0-1 acc: 1.00,[1.0, 1.0] / 1.994170 ✗ (2)\n",
            "266000 88% loss: 0.0167, 0-1 acc: 1.00,[4.0, 7.0] / 10.964309 ✗ (11)\n",
            "267000 89% loss: 0.0178, 0-1 acc: 1.00,[8.0, 3.0, 9.0, 7.0] / 26.932981 ✗ (27)\n",
            "268000 89% loss: 0.0190, 0-1 acc: 1.00,[7.0, 5.0] / 12.006756 ✗ (12)\n",
            "269000 89% loss: 0.0166, 0-1 acc: 1.00,[0.0, 2.0, 7.0, 8.0, 3.0] / 20.071909 ✗ (20)\n",
            "270000 90% loss: 0.0180, 0-1 acc: 1.00,[0.0, 8.0, 6.0, 4.0, 6.0] / 24.064503 ✗ (24)\n",
            "271000 90% loss: 0.0178, 0-1 acc: 1.00,[3.0, 4.0] / 7.023375 ✗ (7)\n",
            "272000 90% loss: 0.0178, 0-1 acc: 1.00,[2.0, 1.0] / 2.998944 ✗ (3)\n",
            "273000 91% loss: 0.0189, 0-1 acc: 1.00,[8.0, 5.0] / 12.951607 ✗ (13)\n",
            "274000 91% loss: 0.0160, 0-1 acc: 1.00,[2.0, 1.0, 8.0, 0.0, 1.0] / 12.004117 ✗ (12)\n",
            "275000 91% loss: 0.0199, 0-1 acc: 1.00,[8.0, 7.0, 0.0] / 15.033704 ✗ (15)\n",
            "276000 92% loss: 0.0198, 0-1 acc: 1.00,[4.0, 9.0, 9.0] / 22.117992 ✗ (22)\n",
            "277000 92% loss: 0.0162, 0-1 acc: 1.00,[9.0, 0.0, 9.0, 5.0, 6.0] / 28.901630 ✗ (29)\n",
            "278000 92% loss: 0.0178, 0-1 acc: 1.00,[0.0, 4.0, 8.0, 9.0] / 21.046167 ✗ (21)\n",
            "279000 93% loss: 0.0184, 0-1 acc: 1.00,[6.0, 0.0, 8.0] / 14.001015 ✗ (14)\n",
            "280000 93% loss: 0.0211, 0-1 acc: 1.00,[8.0, 2.0, 0.0] / 9.983854 ✗ (10)\n",
            "281000 93% loss: 0.0161, 0-1 acc: 1.00,[5.0, 1.0, 8.0, 1.0, 2.0] / 17.016834 ✗ (17)\n",
            "282000 94% loss: 0.0190, 0-1 acc: 1.00,[9.0, 7.0] / 15.949931 ✗ (16)\n",
            "283000 94% loss: 0.0170, 0-1 acc: 1.00,[0.0, 5.0, 3.0, 1.0, 9.0] / 18.215569 ✗ (18)\n",
            "284000 94% loss: 0.0170, 0-1 acc: 1.00,[8.0, 5.0, 8.0, 0.0, 7.0] / 28.103401 ✗ (28)\n",
            "285000 95% loss: 0.0175, 0-1 acc: 1.00,[5.0, 2.0] / 6.988255 ✗ (7)\n",
            "286000 95% loss: 0.0168, 0-1 acc: 1.00,[0.0, 2.0, 6.0, 4.0, 3.0] / 14.911119 ✗ (15)\n",
            "287000 95% loss: 0.0175, 0-1 acc: 1.00,[0.0, 9.0, 9.0, 3.0, 7.0] / 27.979254 ✗ (28)\n",
            "288000 96% loss: 0.0202, 0-1 acc: 1.00,[3.0, 2.0] / 4.961510 ✗ (5)\n",
            "289000 96% loss: 0.0186, 0-1 acc: 1.00,[6.0, 7.0, 5.0] / 18.042740 ✗ (18)\n",
            "290000 96% loss: 0.0178, 0-1 acc: 1.00,[8.0, 1.0, 3.0] / 11.977445 ✗ (12)\n",
            "291000 97% loss: 0.0182, 0-1 acc: 1.00,[4.0, 5.0, 1.0] / 10.001617 ✗ (10)\n",
            "292000 97% loss: 0.0168, 0-1 acc: 1.00,[4.0, 5.0, 8.0, 7.0, 6.0] / 30.322739 ✗ (30)\n",
            "293000 97% loss: 0.0171, 0-1 acc: 1.00,[0.0, 7.0] / 7.015493 ✗ (7)\n",
            "294000 98% loss: 0.0204, 0-1 acc: 1.00,[8.0, 7.0] / 15.054209 ✗ (15)\n",
            "295000 98% loss: 0.0182, 0-1 acc: 1.00,[4.0, 4.0, 3.0] / 10.911388 ✗ (11)\n",
            "296000 98% loss: 0.0189, 0-1 acc: 1.00,[3.0, 4.0, 3.0, 4.0] / 14.066669 ✗ (14)\n",
            "297000 99% loss: 0.0189, 0-1 acc: 1.00,[8.0, 9.0, 2.0] / 19.010904 ✗ (19)\n",
            "298000 99% loss: 0.0179, 0-1 acc: 1.00,[1.0, 6.0, 7.0] / 13.911971 ✗ (14)\n",
            "299000 99% loss: 0.0188, 0-1 acc: 1.00,[5.0, 7.0, 5.0] / 16.910912 ✗ (17)\n",
            "RMSE: 0.060736\n",
            "Pearson Correlation (0.9999672674274933, 0.0)\n",
            "Numbers=[3.0, 3.0, 5.0, 2.0, 5.0, 1.0], Expected=19, Predicted=19.042953491210938\n",
            "Numbers=[7.0, 2.0, 5.0, 1.0, 3.0, 1.0], Expected=19, Predicted=19.00261116027832\n",
            "Numbers=[3.0, 3.0, 0.0, 7.0, 8.0, 2.0], Expected=23, Predicted=22.9910945892334\n",
            "Numbers=[8.0, 8.0, 7.0, 6.0, 5.0, 5.0], Expected=39, Predicted=38.996055603027344\n",
            "Numbers=[0.0, 5.0, 1.0, 9.0, 9.0, 9.0], Expected=33, Predicted=32.89759826660156\n",
            "Numbers=[6.0, 8.0, 5.0, 7.0, 9.0, 0.0], Expected=35, Predicted=34.94171142578125\n",
            "Numbers=[2.0, 3.0, 8.0, 3.0, 7.0, 1.0], Expected=24, Predicted=23.909029006958008\n",
            "Numbers=[1.0, 7.0, 6.0, 9.0, 7.0, 9.0], Expected=39, Predicted=38.95956039428711\n",
            "Numbers=[9.0, 2.0, 6.0, 0.0, 6.0, 9.0], Expected=32, Predicted=31.92533302307129\n",
            "Numbers=[0.0, 6.0, 3.0, 4.0, 4.0, 0.0], Expected=17, Predicted=16.94846534729004\n",
            "Numbers=[0.0, 7.0, 0.0, 7.0, 3.0, 7.0], Expected=24, Predicted=24.089855194091797\n",
            "Numbers=[5.0, 2.0, 2.0, 1.0, 7.0, 8.0], Expected=25, Predicted=24.92891502380371\n",
            "Numbers=[0.0, 9.0, 9.0, 9.0, 4.0, 0.0], Expected=31, Predicted=30.958505630493164\n",
            "Numbers=[0.0, 6.0, 7.0, 0.0, 3.0, 5.0], Expected=21, Predicted=20.996246337890625\n",
            "Numbers=[8.0, 2.0, 8.0, 9.0, 7.0, 3.0], Expected=37, Predicted=37.03901290893555\n",
            "Numbers=[8.0, 1.0, 4.0, 4.0, 0.0, 9.0], Expected=26, Predicted=26.050064086914062\n",
            "Numbers=[6.0, 2.0, 9.0, 5.0, 0.0, 8.0], Expected=30, Predicted=29.947904586791992\n",
            "Numbers=[6.0, 2.0, 4.0, 5.0, 6.0, 7.0], Expected=30, Predicted=30.04230308532715\n",
            "Numbers=[1.0, 7.0, 6.0, 6.0, 0.0, 5.0], Expected=25, Predicted=24.863656997680664\n",
            "Numbers=[6.0, 7.0, 9.0, 8.0, 6.0, 0.0], Expected=36, Predicted=35.965721130371094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsnnqwMUuXyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}